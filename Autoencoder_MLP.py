# -*- coding: utf-8 -*-
"""Proyecto6_MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d6MO_ec3EvUoWbK4Iw_Ka-c-VmS83XpH

## ***Clean GPU***
"""

import gc
gc.collect()
torch.cuda.empty_cache()

"""## ***Packages***"""

import torch
import torch.nn as nn 
import torch.optim as optim 
from torchvision import datasets 
from torchvision import transforms
from torch.utils.data import Subset, DataLoader
from torch.utils.data import Dataset # to custom class dataset
from torchvision.io import read_image # ?
import torch.nn.functional as F

import matplotlib.pyplot as plt
import numpy as np
import os
import cv2
from PIL import Image
import random
import datetime
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold

device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))
print(f"Training on device {device}.")

"""## ***Build Dataset***"""

my_transform = transforms.Compose([
                                   transforms.Resize((256, 256)),
                                   transforms.ToTensor()
                                  ])

path_image_cleaned = "/content/drive/MyDrive/Colab Notebooks/UTEC - IA/data/project6/train_cleaned"
path_image_train = "/content/drive/MyDrive/Colab Notebooks/UTEC - IA/data/project6/train"
path_image_test = "/content/drive/MyDrive/Colab Notebooks/UTEC - IA/data/project6/test"
path_models = "/content/drive/MyDrive/Colab Notebooks/UTEC - IA/models/"

img = read_image(path_image_cleaned+"/2.png")
plt.imshow(img.squeeze())

def load_images_from_folder(folder, my_transform):
    data = []
    for f in sorted(os.listdir(folder + '/')):
        img = Image.open(folder + '/' + f)
        img = my_transform(img)
        img = img.squeeze()
        data.append(img.type(torch.float32))
    return data

data_cleaned = load_images_from_folder(path_image_cleaned, my_transform)
data_train = load_images_from_folder(path_image_train, my_transform)
data_test = load_images_from_folder(path_image_test, my_transform)

tensor_cleaned = torch.stack(data_cleaned)
tensor_train = torch.stack(data_train)
tensor_test = torch.stack(data_test)

shape_img = data_test[0].shape
shape_img

plt.imshow(tensor_cleaned[0])

data_cleaned[0].shape

def check_size(data_file):
  minx, miny, maxx, maxy = 1000, 1000, 0, 0
  for img in data_file:
    minx = min(minx, img.shape[0])
    miny = min(miny, img.shape[1])
    maxx = max(maxx, img.shape[0])
    maxy = max(maxy, img.shape[1])
  print(minx,miny,maxx,maxy)

index= np.arange(0,tensor_cleaned.shape[0])
torch_index = torch.from_numpy(index)
torch_index
#tensor_train.shape

#train_loader = DataLoader(data_train, shuffle=False, batch_size= 4)
#cleaned_loader = DataLoader(data_cleaned, shuffle=False, batch_size= 4)
index_loader = DataLoader(torch_index, shuffle=True, batch_size= 4)

plt.imshow(data_cleaned[0])

"""## ***Model MLP***"""

class AutoencoderMLP(nn.Module):
    def __init__(self, input_shape):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_shape, 1500),
            nn.ReLU(),
            nn.Linear(1500, 4000),
            nn.ReLU(),
        )
        self.decoder = nn.Sequential(
            nn.Linear(4000, 1500),
            nn.ReLU(),
            nn.Linear(1500, input_shape),
            nn.Sigmoid(),
        )

    def forward(self, input):
        out = self.encoder(input)
        out = self.decoder(out)
        return out

class AutoencoderMLP2(nn.Module):
    def __init__(self, input_shape):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_shape, 1500),
            nn.BatchNorm1d(1500),
            nn.LeakyReLU(),
            #nn.Dropout(p = 0.2),
            nn.Linear(1500, 1500),
            nn.BatchNorm1d(1500),
            nn.LeakyReLU(),
            nn.BatchNorm1d(1500),
            #nn.Dropout(p = 0.2),
        )
        self.decoder = nn.Sequential(
            nn.Linear(1500, 1500),
            nn.BatchNorm1d(1500),
            nn.LeakyReLU(),
            #nn.Dropout(p = 0.2),
            nn.Linear(1500, input_shape),
            #nn.BatchNorm1d(input_shape),
            nn.Sigmoid(),
        )

    def forward(self, input):
        out = self.encoder(input)
        out = self.decoder(out)
        return out

"""## ***Traning and Validate Functions***"""

def training_loop(n_epochs, optimizer, model, loss_fn, index_loader, t_train, t_cleaned, features):
  errors = []
  accuracies = []
  tran1_tmp = transforms.ToPILImage()
  for epoch in range(1, n_epochs + 1):
    loss_train = 0.0
    
    for ind in index_loader:
      #plt.imshow(imgs[0].permute(1, 2, 0))
      #plt.show()
      imgs = t_train[ind]
      img_out = imgs[0]
      imgs = imgs.view(-1, features[0]*features[1]).to(device)
      out = t_cleaned[ind]
      out_out = out[0]
      out = out.view(-1, features[0]*features[1]).to(device)
      #print(imgs.shape)
      outputs = model(imgs)
      
      loss = loss_fn(outputs, out)

      optimizer.zero_grad()
      loss.backward()
      optimizer.step()

      loss_train += loss.item()

    if epoch == 1 or epoch % 10 == 0:
      print('{} Epoch {}, Training loss {}'.format( datetime.datetime.now(), epoch, 
                                                   loss_train / t_train.shape[0]))  
      errors.append(loss_train / t_train.shape[0])
      out2 = outputs[0]
      out2 = out2.view(features[0],features[1]).to("cpu")
      display(tran1_tmp(img_out))
      display(tran1_tmp(out2))
      
      #val = validate_age(model, t_train, t_cleaned, k_value)
      #accuracies.append(val)
  return errors, accuracies

"""## ***Training Model MLP***"""

model = AutoencoderMLP(input_shape=shape_img[0]*shape_img[1]).to(device)
optimizer = optim.Adam(model.parameters(), lr=1e-5)
loss_fn = nn.MSELoss()

#model
weights = sum(p.numel() for p in model.parameters())
weights/10**6

model

errors_cnn0, accuracies_cnn0 = training_loop( 
    n_epochs = 500,
    optimizer = optimizer,
    model = model,
    loss_fn = loss_fn,
    index_loader = index_loader,
    t_cleaned = tensor_cleaned,
    t_train = tensor_train,
    features = shape_img,
    )



model = AutoencoderMLP(input_shape=shape_img[0]*shape_img[1]).to(device)
model.load_state_dict(torch.load(path_models+"autoencoder_mlp1.pt"), strict=False)

errors_cnn0 = np.array(errors_cnn0)

#ind_max_lin = np.argmax(accuracies_cnn0[:, 1]) 
#max_lin = np.max(accuracies_cnn0[:, 1])
plt.plot(errors_cnn0)
plt.xlabel("Época x 10")
plt.ylabel("Error sobre entrenamiento")
#plt.text(ind_max_lin + .2, 0.6, 'época='+str(ind_max_lin))
#plt.text(ind_max_lin + .2, 0.4, 'error='+str(errors_cnn0[ind_max_lin]))
#plt.vlines(ind_max_lin, 0, max_lin, linestyles='dashed', colors='red', label="Highest Accuracy")
plt.title("Error por MLP Shallow Undercome")
plt.show()

tran1_tmp = transforms.ToPILImage()
cont = 0
for img in data_test:
  display(tran1_tmp(img))
  img = img.view(-1, 256*256).to(device)
  print(img.shape)
  out = model(img)
  out = out.view(256,256).to("cpu")
  display(tran1_tmp(out))
  cont += 1
  if cont == 5:
    break

img = data_train[0]
img = img.view(-1, 420*540).to(device)

out = model(img)
out = out.view(420,540).to("cpu")
out.shape

tran1_tmp = transforms.ToPILImage()
tran1_tmp(out)

